# ðŸ”® QA Failure Prediction (Pandas + PyTorch + SQLite + Azure ML)

Predictive QA Risk Analytics for Test Automation.

This project trains a lightweight PyTorch model to estimate the probability that each automated test will fail on the next execution. 
Data is stored and retrieved from a **SQLite database**, demonstrating how QA data can be managed, analyzed, and used for intelligent prediction. 
The goal is to help QA teams prioritize what to re-test before release.

---

## ðŸš€ What it does

1. Ingests historical automated test results (pass/fail, severity, flakiness, module) into a SQLite database.
2. Builds features with **Pandas** and **scikit-learn** (module, severity, instability, duration, etc.).
3. Trains a simple neural network classifier in **PyTorch** to predict future test failures.
4. Saves both preprocessing and model artifacts for reuse.
5. Runs inference to estimate failure risk per test and writes predictions back into the SQLite database.
6. Exports a ranked "high-risk test list" for QA leads and release managers.
7. (Optional) Run the training in **Azure ML Studio** for cloud scalability and reproducibility.

This is not about generating tests. It's about **predicting where you're most likely to break next.**

---

## ðŸ§  Why it matters

- Instead of running thousands of regression tests blindly, QA teams can focus on the tests and modules most likely to fail.
- Supports **risk-based testing**, **go/no-go decisions**, and **manual validation prioritization**.
- Demonstrates how QA data can be transformed into actionable insights with ML and SQL.

---

## ðŸ§© Tech stack

- **Python / Pandas** â†’ data preparation and analytics
- **scikit-learn** â†’ feature encoding and preprocessing
- **PyTorch** â†’ model training and inference
- **SQLite** â†’ persistent storage for QA data and predictions
- **Azure ML Studio** (optional) â†’ run model training and experiments in the cloud
- **joblib** â†’ save preprocessor pipeline

---
# Deployed on Azure Cloud

[![Azure ML Workspace](https://img.shields.io/badge/Azure%20ML-View%20Cloud%20Run-blue?logo=microsoftazure)](https://ml.azure.com/runs/e7f297f5-2a77-48ad-ab3c-a1e4834bc8e7?wsid=YOUR_WORKSPACE_ID&tid=YOUR_TENANT_ID)

- â˜ï¸ **Cloud Execution:** [Azure ML Run Link](https://ml.azure.com/experiments/id/f77444f0-37a6-44f3-a07c-c9f5875bd8ad/runs/fc04c3c7-7b2e-44bb-aeee-555aeef0c991?wsid=/subscriptions/77e74c0f-a543-45d6-9cbb-2fa105310285/resourceGroups/Azuregroup/providers/Microsoft.MachineLearningServices/workspaces/qa-failure-prediction-azure&tid=5f8ff547-b6a6-4ad4-9693-814aeb0c6600#metrics)
- ðŸ“‚ **Artifacts:** [Azure Artifacts](https://ml.azure.com/experiments/id/f77444f0-37a6-44f3-a07c-c9f5875bd8ad/runs/fc04c3c7-7b2e-44bb-aeee-555aeef0c991?wsid=/subscriptions/77e74c0f-a543-45d6-9cbb-2fa105310285/resourceGroups/Azuregroup/providers/Microsoft.MachineLearningServices/workspaces/qa-failure-prediction-azure&tid=5f8ff547-b6a6-4ad4-9693-814aeb0c6600#outputsAndLogs)
  - `inputs/training_input_data.csv` â†’ QA dataset versioned for traceability
  - `outputs/predicted_risk_report.csv` â†’ Machine-readable test risk results
  - `outputs/predicted_risk_report.md` â†’ Human-readable summary with test risk levels

---
## ðŸ“‚ Project layout

```text
qa-failure-prediction-azure/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ seed_test_run_history.csv    # initial CSV data (used to populate DB)
â”‚   â””â”€â”€ qa_runs.db                   # SQLite database storing QA data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ init_db.py                   # initializes the SQLite database and tables
â”‚   â”œâ”€â”€ prepare_data.py              # loads data from SQLite + feature engineering
â”‚   â”œâ”€â”€ model.py                     # PyTorch binary classifier
â”‚   â”œâ”€â”€ train.py                     # model training + evaluation + saving artifacts
â”‚   â”œâ”€â”€ infer.py                     # predicts failure probabilities + writes to DB
â”‚   â””â”€â”€ export_report.py             # exports human-readable QA risk reports
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ§± Database schema (SQLite)

**Table 1 â€” `test_run_history`**
Historical test execution data used for training.

| Column | Type | Description |
|---------|------|-------------|
| test_name | TEXT | Name of the test |
| module | TEXT | Functional module (auth, payment, etc.) |
| execution_time_ms | INTEGER | Execution duration |
| failed_last_run | INTEGER | Whether the last run failed |
| failed_last_3_runs | INTEGER | Number of failures in last 3 runs |
| flaky | INTEGER | Flakiness indicator (1 = unstable) |
| bug_severity | TEXT | Severity of the issue |
| last_status | TEXT | Status in the last run (pass/fail) |
| will_fail_next_run | INTEGER | Label (1 if test failed next run) |

**Table 2 â€” `predicted_risks`**
Stores predictions generated by the trained PyTorch model.

| Column | Type | Description |
|---------|------|-------------|
| test_name | TEXT | Test identifier |
| module | TEXT | Functional area |
| bug_severity | TEXT | Severity classification |
| failed_last_run | INTEGER | Last run result |
| failed_last_3_runs | INTEGER | Count of failures in last runs |
| flaky | INTEGER | Whether test is flaky |
| predicted_fail_probability | REAL | Model-estimated failure probability |
| risk_level | TEXT | Categorical risk (LOW / MEDIUM / HIGH) |

---

## âš™ï¸ Workflow

### 1ï¸âƒ£ Initialize the database
Load sample data from CSV and create the SQLite schema.
```bash
python ./src/init_db.py
```

### 2ï¸âƒ£ Train the model
Train and evaluate a PyTorch classifier on the historical QA data.
```bash
python ./src/train.py
```

### 3ï¸âƒ£ Predict risks
Run inference using the trained model and update the database with predictions.
```bash
python ./src/infer.py
```

### 4ï¸âƒ£ Export reports
Generate human-readable QA risk summaries (CSV + Markdown).
```bash[README.md](../ai-test-intelligence/README.md)
python ./src/export_report.py
```

Result:
- `predicted_risk_report.csv`
- `predicted_risk_report.md`
- Predictions also persisted into `predicted_risks` table in SQLite.

---

## ðŸ” Example output

```text
test_name              module     predicted_fail_probability  risk_level
---------------------  ---------- --------------------------- ----------
test_checkout_card     payment    0.91                        HIGH
test_login_mfa         auth       0.82                        HIGH
test_change_password   account    0.75                        HIGH
test_payment_3ds_flow  payment    0.62                        MEDIUM
test_password_reset    auth       0.33                        LOW
```

---

## â˜ï¸ Azure ML Integration

- Upload `data/qa_runs.db` and `notebooks/train_in_azure_ml.ipynb` into **Azure ML Studio**.
- Configure a compute instance or cluster.
- Run the notebook to train the model remotely, track metrics, and register the model in Azure ML.

Example claim for your resume:
> Trained and evaluated a PyTorch-based QA failure prediction model using Azure ML, leveraging Pandas and SQLite data pipelines to forecast high-risk tests before release.

---

## ðŸ“Š Key outcomes

- âœ… Predictive analytics applied to QA execution data  
- âœ… Integration of PyTorch, Pandas, and SQL  
- âœ… Full ML pipeline (data â†’ model â†’ prediction â†’ storage â†’ reporting)  
- âœ… Optional deployment to Azure ML Studio for scalability  

---

## ðŸ“œ License
MIT License Â© 2025 David Garcia  
For educational and demonstration purposes.
